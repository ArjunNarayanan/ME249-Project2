{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.990099\n",
      "1    0.990099\n",
      "2    0.990099\n",
      "3    1.000000\n",
      "4    0.990099\n",
      "5    1.000000\n",
      "6    1.188119\n",
      "7    1.782178\n",
      "Name: x01, dtype: float64 0    0.896552\n",
      "1    1.000000\n",
      "2    1.055172\n",
      "3    0.896552\n",
      "4    1.000000\n",
      "5    1.055172\n",
      "6    0.896552\n",
      "7    1.000000\n",
      "Name: x02, dtype: float64 0    1.009091\n",
      "1    1.000000\n",
      "2    0.993506\n",
      "3    1.009091\n",
      "4    1.000000\n",
      "5    0.993506\n",
      "6    1.009091\n",
      "7    1.000000\n",
      "Name: x03, dtype: float64 0    0.955835\n",
      "1    0.996883\n",
      "2    0.972192\n",
      "3    0.953983\n",
      "4    1.003055\n",
      "5    0.969106\n",
      "6    1.098423\n",
      "7    1.432055\n",
      "Name: y3, dtype: float64\n",
      "[[0.9900990099009901, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [0.9900990099009901, 1.0551724137931036, 0.9935064935064936], [1.0, 0.896551724137931, 1.009090909090909], [0.9900990099009901, 1.0, 1.0], [1.0, 1.0551724137931036, 0.9935064935064936], [1.188118811881188, 0.896551724137931, 1.009090909090909], [1.7821782178217822, 1.0, 1.0]]\n",
      "[[0.99009901 0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [0.99009901 1.05517241 0.99350649]\n",
      " [1.         0.89655172 1.00909091]\n",
      " [0.99009901 1.         1.        ]\n",
      " [1.         1.05517241 0.99350649]\n",
      " [1.18811881 0.89655172 1.00909091]\n",
      " [1.78217822 1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP2.2\n",
    "    V.P. Carey ME249, Spring 2021\n",
    "\n",
    "Intro to Neural Network Modeling \n",
    "Keras model for comparison with first principles model'''\n",
    "\n",
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "\n",
    "#the follwoing 2 lines are only needed for Mac OS machines\n",
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#raw data in dictionary form x01, x02, x03, y3\n",
    "my_dict = { \n",
    "    'x01' : [20., 20., 20., 20.2, 20., 20.2, 24.0, 36.],\n",
    "    'x02' : [13., 14.5, 15.3, 13., 14.5, 15.3, 13., 14.5],\n",
    "    'x03' : [310.8, 308.0, 306.0, 310.8, 308.0, 306.0, 310.8, 308.0],\n",
    "    'y3' : [30.97, 32.3, 31.5, 30.91, 32.5, 31.4, 35.59, 46.4]\n",
    "}\n",
    "#normalized inputs in array\n",
    "xdata = []\n",
    "xdata = [[20./20.2, 13.0/14.5, 310.8/308.0], [20./20.2, 14.5/14.5, 308.0/308.0]] \n",
    "xdata.append([20./20.2, 15.3/14.5, 306.0/308.0])\n",
    "xdata.append([20.2/20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([20./20.2, 14.5/14.5, 308.0/308.0]) \n",
    "xdata.append([20.2/20.2, 15.3/14.5, 306.0/308.0]) \n",
    "xdata.append([24./20.2, 13.0/14.5, 310.8/308.0]) \n",
    "xdata.append([36./20.2, 14.5/14.5, 308.0/308.0]) \n",
    "#data frame\n",
    "df = pd.DataFrame(my_dict)\n",
    "#devide by the median to normalize \n",
    "df.x01= df.x01/20.2\n",
    "df.x02= df.x02/14.5\n",
    "df.x03= df.x03/308.0\n",
    "#normalize output array\n",
    "df.y3= df.y3/32.401\n",
    "df.head\n",
    "print (df.x01, df.x02, df.x03, df.y3)\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "print (xdata)\n",
    "print (xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "#As seen below, we have created three dense layers each with just one neuron. \n",
    "#A dense layer is a layer in neural network that’s fully connected. \n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 3 in this case. \n",
    "#The activation function we have chosen is ReLU, which stands for rectified linear unit.\n",
    "\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 1.2\n",
    "initializer = tf.keras.initializers.RandomUniform(minval= -0.2, maxval=1.2)\n",
    "\n",
    "# define three layer model with one neuron in each layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, activation=K.elu, input_shape=[3]),\n",
    "    keras.layers.Dense(1, activation=K.elu),\n",
    "    keras.layers.Dense(1, activation=K.elu)\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weights in the input layer\n",
    "model.layers[0].set_weights([np.array([[1.8],[0.55],[1]]),np.array([-0.2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weights in first hidden layer\n",
    "model.layers[1].set_weights([np.array([[0.9]]),np.array([-0.07])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weights in output layer\n",
    "model.layers[2].set_weights([np.array([[0.4]]),np.array([0.05])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation. \n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks. \n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here \n",
    "#is mean absolute error. After the compilation of the model, we’ll use the fit method with 100 epochs.\n",
    "\n",
    "#Running model.fit successive times extends the calculation to addtional epochs.\n",
    "\n",
    "sgd = keras.optimizers.RMSprop(learning_rate=0.1)\n",
    "model.compile(loss='mean_absolute_error',optimizer=sgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training. \n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again. \n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs \n",
    "#I found acceptable prediction accuracy.\n",
    "\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs. \n",
    "#During model training, if all the batches of data are seen by the model once, \n",
    "#we say that one epoch has been completed.\n",
    "\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss', \n",
    "    mode='min', \n",
    "    patience = 20, \n",
    "    restore_best_weights = True, \n",
    "    verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss', \n",
    "                     mode='min',  verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.1794\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.17939, saving model to best_model.SB\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 683us/step - loss: 1.2273\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.17939\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 510us/step - loss: 0.9441\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.17939\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 701us/step - loss: 0.4685\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.17939\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4644\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.17939\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6243\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.17939\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1885\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.17939\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6093\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.17939\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3530\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.17939\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1215\n",
      "\n",
      "Epoch 00010: loss improved from 0.17939 to 0.12153, saving model to best_model.SB\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 311us/step - loss: 0.4529\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.12153\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.1026\n",
      "\n",
      "Epoch 00012: loss improved from 0.12153 to 0.10259, saving model to best_model.SB\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 454us/step - loss: 0.4863\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.10259\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 353us/step - loss: 0.2340\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.10259\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 730us/step - loss: 0.1806\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.10259\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 496us/step - loss: 0.3222\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.10259\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 408us/step - loss: 0.0504\n",
      "\n",
      "Epoch 00017: loss improved from 0.10259 to 0.05038, saving model to best_model.SB\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 552us/step - loss: 0.1906\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.05038\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2309\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.05038\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 486us/step - loss: 0.2828\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.05038\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 522us/step - loss: 0.0708\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.05038\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 651us/step - loss: 0.2503\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.05038\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 654us/step - loss: 0.1064\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.05038\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 488us/step - loss: 0.2197\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.05038\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 472us/step - loss: 0.1389\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.05038\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 487us/step - loss: 0.1908\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.05038\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 693us/step - loss: 0.1789\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.05038\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 633us/step - loss: 0.2721\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.05038\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0603\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.05038\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 445us/step - loss: 0.1601\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.05038\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 444us/step - loss: 0.2001\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.05038\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 655us/step - loss: 0.2396\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.05038\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 701us/step - loss: 0.0732\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.05038\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 417us/step - loss: 0.1323\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.05038\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 551us/step - loss: 0.2120\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.05038\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 672us/step - loss: 0.2081\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.05038\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 526us/step - loss: 0.0867\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.05038\n",
      "Epoch 00037: early stopping\n",
      "best epoch =  17\n",
      "smallest loss = 0.05038422346115112\n"
     ]
    }
   ],
   "source": [
    "historyData = model.fit(xarray,df.y3,epochs=100,callbacks=[es,mc])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.1906\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.05038\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 496us/step - loss: 0.0599\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.05038\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 428us/step - loss: 0.0725\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.05038\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 531us/step - loss: 0.0443\n",
      "\n",
      "Epoch 00004: loss improved from 0.05038 to 0.04432, saving model to best_model.SB\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 439us/step - loss: 0.0439\n",
      "\n",
      "Epoch 00005: loss improved from 0.04432 to 0.04387, saving model to best_model.SB\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0434\n",
      "\n",
      "Epoch 00006: loss improved from 0.04387 to 0.04339, saving model to best_model.SB\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 477us/step - loss: 0.0430\n",
      "\n",
      "Epoch 00007: loss improved from 0.04339 to 0.04302, saving model to best_model.SB\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 579us/step - loss: 0.0438\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.04302\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0432\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.04302\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0426\n",
      "\n",
      "Epoch 00010: loss improved from 0.04302 to 0.04262, saving model to best_model.SB\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 950us/step - loss: 0.0420\n",
      "\n",
      "Epoch 00011: loss improved from 0.04262 to 0.04199, saving model to best_model.SB\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 679us/step - loss: 0.0423\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.04199\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0425\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.04199\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0417\n",
      "\n",
      "Epoch 00014: loss improved from 0.04199 to 0.04174, saving model to best_model.SB\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0410\n",
      "\n",
      "Epoch 00015: loss improved from 0.04174 to 0.04097, saving model to best_model.SB\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 638us/step - loss: 0.0401\n",
      "\n",
      "Epoch 00016: loss improved from 0.04097 to 0.04014, saving model to best_model.SB\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 370us/step - loss: 0.0419\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.04014\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0714\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.04014\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 662us/step - loss: 0.0612\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.04014\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0410\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.04014\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0391\n",
      "\n",
      "Epoch 00021: loss improved from 0.04014 to 0.03914, saving model to best_model.SB\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0397\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.03914\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0392\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.03914\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0386\n",
      "\n",
      "Epoch 00024: loss improved from 0.03914 to 0.03859, saving model to best_model.SB\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0380\n",
      "\n",
      "Epoch 00025: loss improved from 0.03859 to 0.03796, saving model to best_model.SB\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0385\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.03796\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0384\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.03796\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 811us/step - loss: 0.0376\n",
      "\n",
      "Epoch 00028: loss improved from 0.03796 to 0.03765, saving model to best_model.SB\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 719us/step - loss: 0.0369\n",
      "\n",
      "Epoch 00029: loss improved from 0.03765 to 0.03687, saving model to best_model.SB\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 557us/step - loss: 0.0364\n",
      "\n",
      "Epoch 00030: loss improved from 0.03687 to 0.03644, saving model to best_model.SB\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0381\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.03644\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 461us/step - loss: 0.0417\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.03644\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 801us/step - loss: 0.0526\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.03644\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0682\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.03644\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 397us/step - loss: 0.0356\n",
      "\n",
      "Epoch 00035: loss improved from 0.03644 to 0.03564, saving model to best_model.SB\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 335us/step - loss: 0.0351\n",
      "\n",
      "Epoch 00036: loss improved from 0.03564 to 0.03510, saving model to best_model.SB\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 450us/step - loss: 0.0345\n",
      "\n",
      "Epoch 00037: loss improved from 0.03510 to 0.03453, saving model to best_model.SB\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 518us/step - loss: 0.0343\n",
      "\n",
      "Epoch 00038: loss improved from 0.03453 to 0.03434, saving model to best_model.SB\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 599us/step - loss: 0.0349\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.03434\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 632us/step - loss: 0.0342\n",
      "\n",
      "Epoch 00040: loss improved from 0.03434 to 0.03419, saving model to best_model.SB\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 560us/step - loss: 0.0335\n",
      "\n",
      "Epoch 00041: loss improved from 0.03419 to 0.03348, saving model to best_model.SB\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 492us/step - loss: 0.0327\n",
      "\n",
      "Epoch 00042: loss improved from 0.03348 to 0.03272, saving model to best_model.SB\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 391us/step - loss: 0.0340\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.03272\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 756us/step - loss: 0.0540\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.03272\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 415us/step - loss: 0.0607\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.03272\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 418us/step - loss: 0.0329\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.03272\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 479us/step - loss: 0.0323\n",
      "\n",
      "Epoch 00047: loss improved from 0.03272 to 0.03233, saving model to best_model.SB\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 355us/step - loss: 0.0317\n",
      "\n",
      "Epoch 00048: loss improved from 0.03233 to 0.03174, saving model to best_model.SB\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0311\n",
      "\n",
      "Epoch 00049: loss improved from 0.03174 to 0.03112, saving model to best_model.SB\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 366us/step - loss: 0.0310\n",
      "\n",
      "Epoch 00050: loss improved from 0.03112 to 0.03096, saving model to best_model.SB\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 791us/step - loss: 0.0314\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.03096\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 436us/step - loss: 0.0307\n",
      "\n",
      "Epoch 00052: loss improved from 0.03096 to 0.03070, saving model to best_model.SB\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.0299\n",
      "\n",
      "Epoch 00053: loss improved from 0.03070 to 0.02992, saving model to best_model.SB\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 315us/step - loss: 0.0292\n",
      "\n",
      "Epoch 00054: loss improved from 0.02992 to 0.02915, saving model to best_model.SB\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 364us/step - loss: 0.0306\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.02915\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 567us/step - loss: 0.0347\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.02915\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00057: loss did not improve from 0.02915\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 762us/step - loss: 0.0404\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.02915\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0375\n",
      "\n",
      "Epoch 00059: loss did not improve from 0.02915\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 837us/step - loss: 0.0407\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.02915\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 708us/step - loss: 0.0318\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.02915\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 742us/step - loss: 0.0303\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.02915\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 691us/step - loss: 0.0290\n",
      "\n",
      "Epoch 00063: loss improved from 0.02915 to 0.02896, saving model to best_model.SB\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 544us/step - loss: 0.0270\n",
      "\n",
      "Epoch 00064: loss improved from 0.02896 to 0.02703, saving model to best_model.SB\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 490us/step - loss: 0.0274\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.02703\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 601us/step - loss: 0.0272\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.02703\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 446us/step - loss: 0.0266\n",
      "\n",
      "Epoch 00067: loss improved from 0.02703 to 0.02663, saving model to best_model.SB\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 417us/step - loss: 0.0260\n",
      "\n",
      "Epoch 00068: loss improved from 0.02663 to 0.02598, saving model to best_model.SB\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 261us/step - loss: 0.0259\n",
      "\n",
      "Epoch 00069: loss improved from 0.02598 to 0.02595, saving model to best_model.SB\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 590us/step - loss: 0.0262\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.02595\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 603us/step - loss: 0.0255\n",
      "\n",
      "Epoch 00071: loss improved from 0.02595 to 0.02547, saving model to best_model.SB\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 384us/step - loss: 0.0247\n",
      "\n",
      "Epoch 00072: loss improved from 0.02547 to 0.02465, saving model to best_model.SB\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 629us/step - loss: 0.0242\n",
      "\n",
      "Epoch 00073: loss improved from 0.02465 to 0.02419, saving model to best_model.SB\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 633us/step - loss: 0.0249\n",
      "\n",
      "Epoch 00074: loss did not improve from 0.02419\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 266us/step - loss: 0.0240\n",
      "\n",
      "Epoch 00075: loss improved from 0.02419 to 0.02400, saving model to best_model.SB\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 392us/step - loss: 0.0230\n",
      "\n",
      "Epoch 00076: loss improved from 0.02400 to 0.02300, saving model to best_model.SB\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 856us/step - loss: 0.0220\n",
      "\n",
      "Epoch 00077: loss improved from 0.02300 to 0.02204, saving model to best_model.SB\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 350us/step - loss: 0.0249\n",
      "\n",
      "Epoch 00078: loss did not improve from 0.02204\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 821us/step - loss: 0.0347\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.02204\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 682us/step - loss: 0.0895\n",
      "\n",
      "Epoch 00080: loss did not improve from 0.02204\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 952us/step - loss: 0.0216\n",
      "\n",
      "Epoch 00081: loss improved from 0.02204 to 0.02159, saving model to best_model.SB\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 766us/step - loss: 0.0210\n",
      "\n",
      "Epoch 00082: loss improved from 0.02159 to 0.02097, saving model to best_model.SB\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 381us/step - loss: 0.0213\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.02097\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 518us/step - loss: 0.0328\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.02097\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0635\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.02097\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 359us/step - loss: 0.0273\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.02097\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 666us/step - loss: 0.0362\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.02097\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 682us/step - loss: 0.0416\n",
      "\n",
      "Epoch 00088: loss did not improve from 0.02097\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 355us/step - loss: 0.0284\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.02097\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 645us/step - loss: 0.0410\n",
      "\n",
      "Epoch 00090: loss did not improve from 0.02097\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 618us/step - loss: 0.0238\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.02097\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0246\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.02097\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 592us/step - loss: 0.0201\n",
      "\n",
      "Epoch 00093: loss improved from 0.02097 to 0.02012, saving model to best_model.SB\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 846us/step - loss: 0.0205\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.02012\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 477us/step - loss: 0.0221\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.02012\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 386us/step - loss: 0.0199\n",
      "\n",
      "Epoch 00096: loss improved from 0.02012 to 0.01993, saving model to best_model.SB\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0195\n",
      "\n",
      "Epoch 00097: loss improved from 0.01993 to 0.01946, saving model to best_model.SB\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 580us/step - loss: 0.0192\n",
      "\n",
      "Epoch 00098: loss improved from 0.01946 to 0.01923, saving model to best_model.SB\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 469us/step - loss: 0.0198\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.01923\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 555us/step - loss: 0.0192\n",
      "\n",
      "Epoch 00100: loss did not improve from 0.01923\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 399us/step - loss: 0.0186\n",
      "\n",
      "Epoch 00101: loss improved from 0.01923 to 0.01865, saving model to best_model.SB\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 508us/step - loss: 0.0181\n",
      "\n",
      "Epoch 00102: loss improved from 0.01865 to 0.01809, saving model to best_model.SB\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 713us/step - loss: 0.0190\n",
      "\n",
      "Epoch 00103: loss did not improve from 0.01809\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 427us/step - loss: 0.0184\n",
      "\n",
      "Epoch 00104: loss did not improve from 0.01809\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 427us/step - loss: 0.0176\n",
      "\n",
      "Epoch 00105: loss improved from 0.01809 to 0.01764, saving model to best_model.SB\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 297us/step - loss: 0.0177\n",
      "\n",
      "Epoch 00106: loss did not improve from 0.01764\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 383us/step - loss: 0.0245\n",
      "\n",
      "Epoch 00107: loss did not improve from 0.01764\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 349us/step - loss: 0.0671\n",
      "\n",
      "Epoch 00108: loss did not improve from 0.01764\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 424us/step - loss: 0.0353\n",
      "\n",
      "Epoch 00109: loss did not improve from 0.01764\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 925us/step - loss: 0.0504\n",
      "\n",
      "Epoch 00110: loss did not improve from 0.01764\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 482us/step - loss: 0.0318\n",
      "\n",
      "Epoch 00111: loss did not improve from 0.01764\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 435us/step - loss: 0.0415\n",
      "\n",
      "Epoch 00112: loss did not improve from 0.01764\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 480us/step - loss: 0.0308\n",
      "\n",
      "Epoch 00113: loss did not improve from 0.01764\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 520us/step - loss: 0.0356\n",
      "\n",
      "Epoch 00114: loss did not improve from 0.01764\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 454us/step - loss: 0.0309\n",
      "\n",
      "Epoch 00115: loss did not improve from 0.01764\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 492us/step - loss: 0.0311\n",
      "\n",
      "Epoch 00116: loss did not improve from 0.01764\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 0s 684us/step - loss: 0.0315\n",
      "\n",
      "Epoch 00117: loss did not improve from 0.01764\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 763us/step - loss: 0.0276\n",
      "\n",
      "Epoch 00118: loss did not improve from 0.01764\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 411us/step - loss: 0.0323\n",
      "\n",
      "Epoch 00119: loss did not improve from 0.01764\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 503us/step - loss: 0.0247\n",
      "\n",
      "Epoch 00120: loss did not improve from 0.01764\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 478us/step - loss: 0.0227\n",
      "\n",
      "Epoch 00121: loss did not improve from 0.01764\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 482us/step - loss: 0.0242\n",
      "\n",
      "Epoch 00122: loss did not improve from 0.01764\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 463us/step - loss: 0.0239\n",
      "\n",
      "Epoch 00123: loss did not improve from 0.01764\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 459us/step - loss: 0.0236\n",
      "\n",
      "Epoch 00124: loss did not improve from 0.01764\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 515us/step - loss: 0.0251\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00125: loss did not improve from 0.01764\n",
      "Epoch 00125: early stopping\n",
      "best epoch =  105\n",
      "smallest loss = 0.017639733850955963\n"
     ]
    }
   ],
   "source": [
    "sgd = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='mean_absolute_error',optimizer=sgd)\n",
    "\n",
    "historyData = model.fit(xarray,df.y3,epochs=200,callbacks=[es,mc])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.0177\n",
      "\n",
      "Epoch 00001: loss did not improve from 0.01764\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0178\n",
      "\n",
      "Epoch 00002: loss did not improve from 0.01764\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0175\n",
      "\n",
      "Epoch 00003: loss improved from 0.01764 to 0.01746, saving model to best_model.SB\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 351us/step - loss: 0.0171\n",
      "\n",
      "Epoch 00004: loss improved from 0.01746 to 0.01714, saving model to best_model.SB\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 284us/step - loss: 0.0168\n",
      "\n",
      "Epoch 00005: loss improved from 0.01714 to 0.01682, saving model to best_model.SB\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 717us/step - loss: 0.0168\n",
      "\n",
      "Epoch 00006: loss improved from 0.01682 to 0.01682, saving model to best_model.SB\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0172\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.01682\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.01682\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 954us/step - loss: 0.0167\n",
      "\n",
      "Epoch 00009: loss improved from 0.01682 to 0.01668, saving model to best_model.SB\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 966us/step - loss: 0.0164\n",
      "\n",
      "Epoch 00010: loss improved from 0.01668 to 0.01643, saving model to best_model.SB\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 825us/step - loss: 0.0162\n",
      "\n",
      "Epoch 00011: loss improved from 0.01643 to 0.01622, saving model to best_model.SB\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.01622\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 683us/step - loss: 0.0165\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.01622\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0163\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.01622\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "\n",
      "Epoch 00015: loss improved from 0.01622 to 0.01610, saving model to best_model.SB\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 415us/step - loss: 0.0159\n",
      "\n",
      "Epoch 00016: loss improved from 0.01610 to 0.01587, saving model to best_model.SB\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 949us/step - loss: 0.0163\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.01587\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.01587\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 723us/step - loss: 0.0160\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.01587\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 760us/step - loss: 0.0158\n",
      "\n",
      "Epoch 00020: loss improved from 0.01587 to 0.01578, saving model to best_model.SB\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 556us/step - loss: 0.0156\n",
      "\n",
      "Epoch 00021: loss improved from 0.01578 to 0.01556, saving model to best_model.SB\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 564us/step - loss: 0.0158\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.01556\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 477us/step - loss: 0.0159\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.01556\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0157\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.01556\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 472us/step - loss: 0.0155\n",
      "\n",
      "Epoch 00025: loss improved from 0.01556 to 0.01547, saving model to best_model.SB\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 445us/step - loss: 0.0153\n",
      "\n",
      "Epoch 00026: loss improved from 0.01547 to 0.01526, saving model to best_model.SB\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0153\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.01526\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 518us/step - loss: 0.0161\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.01526\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 607us/step - loss: 0.0152\n",
      "\n",
      "Epoch 00029: loss improved from 0.01526 to 0.01516, saving model to best_model.SB\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 399us/step - loss: 0.0158\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.01516\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 924us/step - loss: 0.0151\n",
      "\n",
      "Epoch 00031: loss improved from 0.01516 to 0.01514, saving model to best_model.SB\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.01514\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.01514\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 438us/step - loss: 0.0153\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.01514\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 417us/step - loss: 0.0152\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.01514\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 898us/step - loss: 0.0151\n",
      "\n",
      "Epoch 00036: loss improved from 0.01514 to 0.01508, saving model to best_model.SB\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 328us/step - loss: 0.0149\n",
      "\n",
      "Epoch 00037: loss improved from 0.01508 to 0.01493, saving model to best_model.SB\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 681us/step - loss: 0.0150\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.01493\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 720us/step - loss: 0.0157\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.01493\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0150\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.01493\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0154\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.01493\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 487us/step - loss: 0.0151\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.01493\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.01493\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 599us/step - loss: 0.0151\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.01493\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 566us/step - loss: 0.0151\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.01493\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 731us/step - loss: 0.0152\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.01493\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 595us/step - loss: 0.0150\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.01493\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 447us/step - loss: 0.0149\n",
      "\n",
      "Epoch 00048: loss improved from 0.01493 to 0.01485, saving model to best_model.SB\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 528us/step - loss: 0.0147\n",
      "\n",
      "Epoch 00049: loss improved from 0.01485 to 0.01473, saving model to best_model.SB\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 599us/step - loss: 0.0147\n",
      "\n",
      "Epoch 00050: loss improved from 0.01473 to 0.01468, saving model to best_model.SB\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 474us/step - loss: 0.0156\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.01468\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "\n",
      "Epoch 00052: loss did not improve from 0.01468\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 726us/step - loss: 0.0155\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.01468\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 604us/step - loss: 0.0148\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.01468\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 596us/step - loss: 0.0153\n",
      "\n",
      "Epoch 00055: loss did not improve from 0.01468\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 525us/step - loss: 0.0149\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.01468\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 664us/step - loss: 0.0152\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.01468\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 625us/step - loss: 0.0150\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.01468\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s 704us/step - loss: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00059: loss did not improve from 0.01468\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 494us/step - loss: 0.0151\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.01468\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.01468\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 569us/step - loss: 0.0152\n",
      "\n",
      "Epoch 00062: loss did not improve from 0.01468\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 673us/step - loss: 0.0148\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.01468\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 427us/step - loss: 0.0153\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.01468\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 543us/step - loss: 0.0147\n",
      "\n",
      "Epoch 00065: loss improved from 0.01468 to 0.01465, saving model to best_model.SB\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 366us/step - loss: 0.0145\n",
      "\n",
      "Epoch 00066: loss improved from 0.01465 to 0.01454, saving model to best_model.SB\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 472us/step - loss: 0.0145\n",
      "\n",
      "Epoch 00067: loss improved from 0.01454 to 0.01446, saving model to best_model.SB\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 668us/step - loss: 0.0156\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.01446\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.01446\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.01446\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 563us/step - loss: 0.0146\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.01446\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 634us/step - loss: 0.0153\n",
      "\n",
      "Epoch 00072: loss did not improve from 0.01446\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 507us/step - loss: 0.0147\n",
      "\n",
      "Epoch 00073: loss did not improve from 0.01446\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 504us/step - loss: 0.0152\n",
      "\n",
      "Epoch 00074: loss did not improve from 0.01446\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 968us/step - loss: 0.0148\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.01446\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 490us/step - loss: 0.0151\n",
      "\n",
      "Epoch 00076: loss did not improve from 0.01446\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 585us/step - loss: 0.0149\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.01446\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 432us/step - loss: 0.0149\n",
      "\n",
      "Epoch 00078: loss did not improve from 0.01446\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 505us/step - loss: 0.0150\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.01446\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 520us/step - loss: 0.0148\n",
      "\n",
      "Epoch 00080: loss did not improve from 0.01446\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 534us/step - loss: 0.0151\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.01446\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 530us/step - loss: 0.0147\n",
      "\n",
      "Epoch 00082: loss did not improve from 0.01446\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 424us/step - loss: 0.0152\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.01446\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 496us/step - loss: 0.0146\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.01446\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 793us/step - loss: 0.0153\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.01446\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 379us/step - loss: 0.0145\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.01446\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 538us/step - loss: 0.0154\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.01446\n",
      "Epoch 00087: early stopping\n",
      "best epoch =  67\n",
      "smallest loss = 0.014456644654273987\n"
     ]
    }
   ],
   "source": [
    "sgd = keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='mean_absolute_error',optimizer=sgd)\n",
    "\n",
    "historyData = model.fit(xarray,df.y3,epochs=200,callbacks=[es,mc])\n",
    "\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.755288  ]\n",
      " [0.18251595]\n",
      " [0.63163596]]\n",
      "w01 =  1.755288 w02 =  0.18251595 w03 =  0.63163596\n",
      "[-0.5691421]\n",
      "b1 =  [-0.5691421]\n",
      "[[0.76431924]]\n",
      "w12 =  0.76431924\n",
      "[-0.23482344]\n",
      "b2 =  [-0.23482344]\n",
      "[[0.43096396]]\n",
      "w23 =  0.43096396\n",
      "[0.41481322]\n",
      "b3 =  [0.41481322]\n",
      "x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:\n",
      "0.9900990099009901 0.896551724137931 1.009090909090909 0.9558346964599856 [[0.9624466]]\n",
      "0.9900990099009901 1.0 1.0 0.9968828122588808 [[0.9667744]]\n",
      "0.9900990099009901 1.0551724137931036 0.9935064935064936 0.9721922162896206 [[0.96874034]]\n",
      "1.0 0.896551724137931 1.009090909090909 0.9539829017622912 [[0.9681711]]\n",
      "0.9900990099009901 1.0 1.0 1.003055461251196 [[0.9667744]]\n",
      "1.0 1.0551724137931036 0.9935064935064936 0.9691058917934631 [[0.9744649]]\n",
      "1.188118811881188 0.896551724137931 1.009090909090909 1.0984228881824636 [[1.0769379]]\n",
      "1.7821782178217822 1.0 1.0 1.4320545662170918 [[1.4247398]]\n",
      "  \n",
      "x01,  x02,   x03,  y3,  a3*32.4:\n",
      "20.0 13.0 310.8 30.969044165303533 [[31.18327]]\n",
      "20.0 14.5 308.0 32.29900311718774 [[31.323492]]\n",
      "20.0 15.3 306.0 31.499027807783705 [[31.387188]]\n",
      "20.2 13.0 310.8 30.909046017098234 [[31.368746]]\n",
      "20.0 14.5 308.0 32.498996944538746 [[31.323492]]\n",
      "20.2 15.3 306.0 31.3990308941082 [[31.572664]]\n",
      "23.999999999999996 13.0 310.8 35.58890157711182 [[34.89279]]\n",
      "36.0 14.5 308.0 46.398567945433776 [[46.16157]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#For results of training network:\n",
    "\n",
    "#keras.layer.get_weights() function retrieves weight values\n",
    "first_layer_weights = model.layers[0].get_weights()[0]\n",
    "w01 = first_layer_weights[0][0]\n",
    "w02 = first_layer_weights[1][0]\n",
    "w03 = first_layer_weights[2][0]\n",
    "first_layer_bias  = model.layers[0].get_weights()[1]\n",
    "b1 = first_layer_bias\n",
    "second_layer_weights = model.layers[1].get_weights()[0]\n",
    "w12 = second_layer_weights[0][0]\n",
    "second_layer_bias  = model.layers[1].get_weights()[1]\n",
    "b2 = second_layer_bias\n",
    "third_layer_weights = model.layers[2].get_weights()[0]\n",
    "w23 = third_layer_weights[0][0]\n",
    "third_layer_bias  = model.layers[2].get_weights()[1]\n",
    "b3 = third_layer_bias\n",
    "\n",
    "#print weights and biases\n",
    "print (first_layer_weights)\n",
    "print ('w01 = ', w01, 'w02 = ', w02, 'w03 = ', w03)\n",
    "print (first_layer_bias)\n",
    "print ('b1 = ', b1)\n",
    "print (second_layer_weights)\n",
    "print ('w12 = ', w12)\n",
    "print (second_layer_bias)\n",
    "print ('b2 = ', b2)\n",
    "print (third_layer_weights)\n",
    "print ('w23 = ', w23)\n",
    "print (third_layer_bias)\n",
    "print ('b3 = ', b3)\n",
    "\n",
    "#use model.predict() function to print model predictions for data conditions\n",
    "xarray= np.array(xdata)\n",
    "print ('x01/20.2,  x02/14.5,   x03/308.0,  y3/32.4,  a3:')\n",
    "test = []\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    print (xarray[i][0], xarray[i][1], xarray[i][2], df.y3[i], a3)\n",
    "print('  ')\n",
    "print ('x01,  x02,   x03,  y3,  a3*32.4:')\n",
    "for i in range(0,8): \n",
    "    test = [[xarray[i][0], xarray[i][1], xarray[i][2]]]\n",
    "    testarray = np.array(test)\n",
    "    a3 = model.predict(testarray)\n",
    "    print (xarray[i][0]*20.2, xarray[i][1]*14.5, xarray[i][2]*308.0, df.y3[i]*32.4, a3*32.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
